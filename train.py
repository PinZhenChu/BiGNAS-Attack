import torch
import logging
from collections import Counter
from torch.utils.data import DataLoader
from sklearn.metrics import roc_auc_score
import torch.nn as nn

from dataset import Dataset
from utils import link_split, load_model
from pytorchtools import EarlyStopping
from auxilearn.optim import MetaOptimizer


def meta_optimizeation(
    target_meta_loader,
    replace_optimizer,
    model,
    args,
    criterion,
    replace_scheduler,
    source_edge_index,
    target_edge_index,
):
    device = args.device
    for batch, (target_link, target_label) in enumerate(target_meta_loader):
        if batch < args.descent_step:
            target_link, target_label = target_link.to(device), target_label.to(device)

            replace_optimizer.zero_grad()
            out = model.meta_prediction(
                source_edge_index, target_edge_index, target_link
            ).squeeze()
            loss_target = criterion(out, target_label).mean()
            loss_target.backward()
            replace_optimizer.step()
        else:
            break
    replace_scheduler.step()


@torch.no_grad()
def evaluate(name, model, source_edge_index, target_edge_index, link, label):
    model.eval()

    out = model(source_edge_index, target_edge_index, link, is_source=False).squeeze()
    try:
        auc = roc_auc_score(label.tolist(), out.tolist())
    except Exception:
        auc = 1.0
    logging.info(f"{name} AUC: {auc:.4f}")

    model.train()
    return auc

def evaluate_multiple_topk(model, data, source_edge_index, target_edge_index, cold_item_set, device):
    topk_list = [10, 15, 20, 25, 30, 40, 50, 60, 70, 80, 90, 100]
    print("\nğŸ“Š Evaluation for multiple top-K values:")
    for k in topk_list:
        hr = evaluate_hit_ratio(
            model=model,
            data=data,
            source_edge_index=source_edge_index,
            target_edge_index=target_edge_index,
            top_k=k,
            num_candidates=99,
            device=device
        )

        er = evaluate_er_hit_ratio(
            model=model,
            data=data,
            source_edge_index=source_edge_index,
            target_edge_index=target_edge_index,
            cold_item_set=cold_item_set,
            top_k=k,
            num_candidates=99,
            device=device
        )

        # print(f"[Top-{k:>3}] HR@{k:<3}: {{hr:.4f}}  |  ER@{k:<3}: {{er:.4f}}")



def get_test_positive_dict(data):
    test_user_item_dict = {}
    test_link = data.target_test_edge_index.cpu()
    for u, i in zip(test_link[0], test_link[1]):
        u, i = u.item(), i.item()
        if u not in test_user_item_dict:
            test_user_item_dict[u] = []
        test_user_item_dict[u].append(i)
    return test_user_item_dict



def evaluate_hit_ratio(
    model, data, source_edge_index, target_edge_index,
    top_k, num_candidates=99,
    device=None
):
    import random
    model.eval()
    hit_count = 0
    all_target_items = set(range(data.num_target_items))

    # å–å¾— test set çš„ user -> positive items å°æ‡‰é—œä¿‚
    user_interactions = get_test_positive_dict(data)
    sim_users = list(user_interactions.keys())  # ä½¿ç”¨ test set users
    logging.info(f"Test set user count: {len(sim_users)}")

    total_users = 0
    source_edge_index = source_edge_index.to(device)
    target_edge_index = target_edge_index.to(device)

    with torch.no_grad():
        for user_id in sim_users:
            pos_items = user_interactions.get(user_id, set())
            if len(pos_items) > 1:
                logging.warning(f"User {user_id} has {len(pos_items)} positives in test set.")

            if len(pos_items) == 0:
                continue

            # é¸ä¸€å€‹æ­£æ¨£æœ¬
            pos_item = list(pos_items)[0]

            # å¾éæ­£æ¨£æœ¬ä¸­æŠ½å–è² æ¨£æœ¬
            negative_pool = list(all_target_items - set(pos_items))
            if len(negative_pool) < num_candidates:
                continue

            sampled_negatives = random.sample(negative_pool, num_candidates)

            # çµ„æˆå€™é¸æ¸…å–®ï¼Œæ­£ä¾‹ + è² ä¾‹ï¼Œä¸¦æ‰“äº‚
            candidate_items = sampled_negatives + [pos_item]
            random.shuffle(candidate_items)

            user_tensor = torch.tensor([user_id] * len(candidate_items), device=device)
            item_tensor = torch.tensor(candidate_items, device=device)
            link = torch.stack([user_tensor, item_tensor], dim=0)

            scores = model(source_edge_index, target_edge_index, link, is_source=False).squeeze()

            top_k_indices = torch.topk(scores, k=top_k).indices.tolist()
            top_k_items = [candidate_items[i] for i in top_k_indices]

            if pos_item in top_k_items:
                hit_count += 1
            total_users += 1

    hit_ratio = hit_count / total_users if total_users > 0 else 0.0
    logging.info(f"[HIT_RATIO@{top_k}] Users={total_users}, Hits={hit_count}, Hit Ratio={hit_ratio:.4f}")
    return hit_ratio


def evaluate_er_hit_ratio(
    model, data, source_edge_index, target_edge_index,
    cold_item_set,
    top_k, num_candidates=99,
    device=None
):
    import random
    model.eval()

    all_target_items = set(range(data.num_target_items))
    user_interactions = get_test_positive_dict(data)
    sim_users = list(user_interactions.keys())

    source_edge_index = source_edge_index.to(device)
    target_edge_index = target_edge_index.to(device)

    total_users = 0
    cold_item_hit_count = 0
    cold_item_ranks = []  # å„²å­˜ cold item è¢«æ’é€²å»æ™‚çš„æ’å

    with torch.no_grad():
        for user_id in sim_users:
            # å»ºç«‹å€™é¸æ± 
            negative_pool = list(all_target_items - cold_item_set)
            if len(negative_pool) < num_candidates:
                continue

            sampled_items = random.sample(negative_pool, num_candidates)
            sampled_items += list(cold_item_set)
            sampled_items = list(set(sampled_items))
            random.shuffle(sampled_items)

            user_tensor = torch.tensor([user_id] * len(sampled_items), device=device)
            item_tensor = torch.tensor(sampled_items, device=device)
            link = torch.stack([user_tensor, item_tensor], dim=0)

            scores = model(source_edge_index, target_edge_index, link, is_source=False).squeeze()
            scores_list = scores.tolist()

            # è¨ˆç®—æ’åº
            item_score_pairs = list(zip(sampled_items, scores_list))
            item_score_pairs.sort(key=lambda x: x[1], reverse=True)
            sorted_items = [item for item, _ in item_score_pairs]

            top_k_items = sorted_items[:top_k]

            # çµ±è¨ˆå‘½ä¸­èˆ‡æ’å
            cold_hits = [item for item in top_k_items if item in cold_item_set]
            if cold_hits:
                cold_item_hit_count += 1
                for cold_item in cold_hits:
                    rank = top_k_items.index(cold_item) + 1  # 1-based rank
                    cold_item_ranks.append(rank)

            total_users += 1

    er_ratio = cold_item_hit_count / total_users if total_users > 0 else 0.0
    avg_rank = sum(cold_item_ranks) / len(cold_item_ranks) if cold_item_ranks else -1
    median_rank = (
        sorted(cold_item_ranks)[len(cold_item_ranks) // 2] if cold_item_ranks else -1
    )

    logging.info(f"[ER@{top_k}] Users={total_users}, Cold Item Hits={cold_item_hit_count}, ER Ratio={er_ratio:.4f}")
    return er_ratio


def train(model, perceptor, data, args, source_edge_index=None):
    device = args.device
    data = data.to(device)
    model = model.to(device)
    perceptor = perceptor.to(device)

    (
        orig_source_edge_index,
        source_label,
        source_link,
        target_train_edge_index,
        target_train_label,
        target_train_link,
        target_valid_link,
        target_valid_label,
        target_test_link,
        target_test_label,
        target_test_edge_index,
    ) = link_split(data)

    if source_edge_index is not None:
        source_edge_index = source_edge_index.to(device)
    else:
        source_edge_index = orig_source_edge_index.to(device)

    source_set_size = source_link.shape[1]
    train_set_size = target_train_link.shape[1]
    val_set_size = target_valid_link.shape[1]
    test_set_size = target_test_link.shape[1]
    logging.info(f"Train set size: {train_set_size}")
    logging.info(f"Valid set size: {val_set_size}")
    logging.info(f"Test set size: {test_set_size}")

    target_train_set = Dataset(
        target_train_link.to("cpu"),
        target_train_label.to("cpu"),
    )
    target_train_loader = DataLoader(
        target_train_set,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        collate_fn=target_train_set.collate_fn,
    )

    source_batch_size = int(args.batch_size * train_set_size / source_set_size)
    source_train_set = Dataset(source_link.to("cpu"), source_label.to("cpu"))
    source_train_loader = DataLoader(
        source_train_set,
        batch_size=source_batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        collate_fn=source_train_set.collate_fn,
    )

    target_meta_loader = DataLoader(
        target_train_set,
        batch_size=args.meta_batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        collate_fn=target_train_set.collate_fn,
    )
    target_meta_iter = iter(target_meta_loader)
    source_meta_batch_size = int(
        args.meta_batch_size * train_set_size / source_set_size
    )
    source_meta_loader = DataLoader(
        source_train_set,
        batch_size=source_meta_batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        collate_fn=source_train_set.collate_fn,
    )

    optimizer = torch.optim.AdamW(
        model.parameters(), lr=args.lr, weight_decay=args.weight_decay
    )
    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=args.epochs
    )

    perceptor_optimizer = torch.optim.Adam(
        perceptor.parameters(), lr=args.lr, weight_decay=args.weight_decay
    )
    meta_optimizer = MetaOptimizer(
        meta_optimizer=perceptor_optimizer,
        hpo_lr=args.hpo_lr,
        truncate_iter=3,
        max_grad_norm=10,
    )

    model_param = [
        param for name, param in model.named_parameters() if "preds" not in name
    ]
    replace_param = [
        param for name, param in model.named_parameters() if name.startswith("replace")
    ]
    replace_optimizer = torch.optim.Adam(replace_param, lr=args.lr)
    replace_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        replace_optimizer, T_max=args.T_max
    )

    early_stopping = EarlyStopping(
        patience=args.patience,
        verbose=True,
        path=args.model_path,
        trace_func=logging.info,
    )

    criterion = nn.BCELoss(reduction="none")
    iteration = 0

    for epoch in range(args.epochs):
        for (source_link, source_label), (target_link, target_label) in zip(
            source_train_loader, target_train_loader
        ):
            torch.cuda.empty_cache()
            source_link = source_link.to(device)
            source_label = source_label.to(device)
            target_link = target_link.to(device)
            target_label = target_label.to(device)
            weight_source = perceptor(source_link[1], source_edge_index, model)

            optimizer.zero_grad()
            source_out = model(
                source_edge_index, target_train_edge_index, source_link, is_source=True
            ).squeeze()
            target_out = model(
                source_edge_index, target_train_edge_index, target_link, is_source=False
            ).squeeze()
            source_loss = (
                criterion(source_out, source_label).reshape(-1, 1) * weight_source
            ).sum()
            target_loss = criterion(target_out, target_label).mean()
            loss = source_loss + target_loss if args.use_meta else target_loss
            loss.backward()
            optimizer.step()

            iteration += 1
            if (
                args.use_source
                and args.use_meta
                and iteration % args.meta_interval == 0
            ):
                logging.info(f"Entering meta optimization, iteration: {iteration}")
                meta_optimizeation(
                    target_meta_loader,
                    replace_optimizer,
                    model,
                    args,
                    criterion,
                    replace_scheduler,
                    source_edge_index,
                    target_train_edge_index,
                )

                try:
                    target_meta_link, target_meta_label = next(target_meta_iter)
                except StopIteration:
                    target_meta_iter = iter(target_meta_loader)
                    target_meta_link, target_meta_label = next(target_meta_iter)

                target_meta_link = target_meta_link.to(device)
                target_meta_label = target_meta_label.to(device)

                optimizer.zero_grad()
                target_out = model(
                    source_edge_index,
                    target_train_edge_index,
                    target_meta_link,
                    is_source=False,
                ).squeeze()
                meta_loss = criterion(target_out, target_meta_label).mean()

                for (source_link, source_label), (target_link, target_label) in zip(
                    source_meta_loader, target_meta_loader
                ):
                    source_link = source_link.to(device)
                    source_label = source_label.to(device)
                    target_link = target_link.to(device)
                    target_label = target_label.to(device)
                    weight_source = perceptor(source_link[1], source_edge_index, model)

                    optimizer.zero_grad()
                    source_out = model(
                        source_edge_index,
                        target_train_edge_index,
                        source_link,
                        is_source=True,
                    ).squeeze()
                    target_out = model(
                        source_edge_index,
                        target_train_edge_index,
                        target_link,
                        is_source=False,
                    ).squeeze()
                    source_loss = (
                        criterion(source_out, source_label).reshape(-1, 1)
                        * weight_source
                    ).sum()
                    target_loss = criterion(target_out, target_label).mean()
                    meta_train_loss = (
                        source_loss + target_loss if args.use_meta else target_loss
                    )
                    break

                torch.cuda.empty_cache()
                meta_optimizer.step(
                    train_loss=meta_train_loss,
                    val_loss=meta_loss,
                    aux_params=list(perceptor.parameters()),
                    parameters=model_param,
                    return_grads=True,
                    entropy=None,
                )

        train_auc = evaluate(
            "Train",
            model,
            source_edge_index,
            target_train_edge_index,
            target_train_link,
            target_train_label,
        )
        val_auc = evaluate(
            "Valid",
            model,
            source_edge_index,
            target_train_edge_index,
            target_valid_link,
            target_valid_label,
        )

        logging.info(
            f"[Epoch: {epoch}] Train Loss: {loss:.4f}, Train AUC: {train_auc:.4f}, Valid AUC: {val_auc:.4f}"
        )

        # å¯é¸é¡å¤–logåˆ° wandbï¼ˆéœ€å…ˆ import wandbï¼‰
        # import wandb
        # wandb.log({"loss": loss, "train_auc": train_auc, "val_auc": val_auc}, step=epoch)

        early_stopping(val_auc, model)
        if early_stopping.early_stop:
            logging.info("Early stopping triggered.")
            break

        lr_scheduler.step()

    # è®€å–æœ€ä½³æ¨¡å‹ã€æ¸¬è©¦è©•ä¼°
    model = load_model(args).to(device)
    evaluate_hit_ratio(
        model=model,
        data=data,
        source_edge_index=source_edge_index,
        target_edge_index=target_train_edge_index,
        top_k=args.top_k,
        num_candidates=99,
        device=device,
    )

    cold_item_id = 2286  # ä½ å¯ä»¥æ”¹æˆè¦è©•ä¼°çš„å†·é–€å•†å“id
    if cold_item_id is not None:
        evaluate_er_hit_ratio(
            model=model,
            data=data,
            source_edge_index=source_edge_index,
            target_edge_index=target_train_edge_index,
            cold_item_set={cold_item_id},
            top_k=args.top_k,
            num_candidates=99,
            device=device,
        )

    test_auc = evaluate(
        "Test",
        model,
        source_edge_index,
        target_train_edge_index,
        target_test_link,
        target_test_label,
    )
    logging.info(f"Test AUC: {test_auc:.4f}")
    evaluate_multiple_topk(
        model=model,
        data=data,
        source_edge_index=source_edge_index,
        target_edge_index=target_train_edge_index,
        cold_item_set={2286},   # æ³¨æ„é€™é‚Šæ˜¯ setï¼Œä¸æ˜¯ cold_item_id=
        device=device
    )


    return model
#######################################################
# import logging

# import torch
# import torch.nn as nn
# import wandb
# from sklearn.metrics import roc_auc_score
# from torch.utils.data import DataLoader

# from auxilearn.optim import MetaOptimizer
# from dataset import Dataset
# from pytorchtools import EarlyStopping
# from utils import link_split, load_model


# def meta_optimizeation(
#     target_meta_loader,
#     replace_optimizer,
#     model,
#     args,
#     criterion,
#     replace_scheduler,
#     source_edge_index,
#     target_edge_index,
# ):
#     device = args.device
#     for batch, (target_link, target_label) in enumerate(target_meta_loader):
#         if batch < args.descent_step:
#             target_link, target_label = target_link.to(device), target_label.to(device)

#             replace_optimizer.zero_grad()
#             out = model.meta_prediction(
#                 source_edge_index, target_edge_index, target_link
#             ).squeeze()
#             loss_target = criterion(out, target_label).mean()
#             loss_target.backward()
#             replace_optimizer.step()
#         else:
#             break
#     replace_scheduler.step()


# @torch.no_grad()
# def evaluate(name, model, source_edge_index, target_edge_index, link, label):
#     model.eval()

#     out = model(source_edge_index, target_edge_index, link, is_source=False).squeeze()
#     try:
#         auc = roc_auc_score(label.tolist(), out.tolist())
#     except:
#         auc = 1.0
#     logging.info(f"{name} AUC: {auc:4f}")

#     model.train()
#     return auc
# def get_test_positive_dict(data):
#     """
#     æ ¹æ“š test linkï¼ˆdata.target_test_linkï¼‰å»ºç«‹ test set user çš„æ­£æ¨£æœ¬å­—å…¸ã€‚
#     å›å‚³: {user_id: [item1, item2, ...]}
#     """
#     test_user_item_dict = {}
#     test_link = data.target_test_link.cpu()
#     for u, i in zip(test_link[0], test_link[1]):
#         u, i = u.item(), i.item()
#         if u not in test_user_item_dict:
#             test_user_item_dict[u] = []
#         test_user_item_dict[u].append(i)
#     return test_user_item_dict

# def evaluate_hit_ratio(
#     model, data, source_edge_index, target_edge_index,
#     top_k, num_candidates=99,
#     device=None
# ):
#     import random
#     model.eval()
#     hit_count = 0
#     all_target_items = set(range(data.num_target_items))

#     # âœ… å–å¾— test set çš„ user -> positive items å°æ‡‰é—œä¿‚
#     user_interactions = get_test_positive_dict(data)
#     sim_users = list(user_interactions.keys())  # ç›´æ¥ä½¿ç”¨ test set çš„ user
#     print(f"âœ… Test set user count: {len(sim_users)}")

#     total_users = 0
#     source_edge_index = source_edge_index.to(device)
#     target_edge_index = target_edge_index.to(device)

#     with torch.no_grad():
#         for user_id in sim_users:
#             pos_items = user_interactions.get(user_id, set())
#             if len(pos_items) > 1:
#                 print(f"âš ï¸ Warning: User {user_id} has {len(pos_items)} positives in test set.")

#             if len(pos_items) == 0:
#                 continue

#             # âœ… ç¬¬ä¸€æ­¥ï¼šé¸æ“‡ä¸€å€‹æ­£æ¨£æœ¬
#             pos_item = list(pos_items)[0]
#             # print(f"\n=== [User {user_id}] ===")
#             # print(f"ğŸ‘‰ Positive item: {pos_item}")

#             # âœ… ç¬¬äºŒæ­¥ï¼šæŒ‘é¸è² æ¨£æœ¬ï¼ˆå¾éæ­£æ¨£æœ¬ä¸­éš¨æ©ŸæŠ½ num_candidates å€‹ï¼‰
#             negative_pool = list(all_target_items - set(pos_items))
#             if len(negative_pool) < num_candidates:
#                 # print(f"âŒ Negative pool too small for user {user_id}, skipping.")
#                 continue

#             sampled_negatives = random.sample(negative_pool, num_candidates)
#             # print(f"ğŸ¯ Sampled {num_candidates} negatives: {sampled_negatives[:10]}...")

#             # âœ… ç¬¬ä¸‰æ­¥ï¼šçµ„æˆå€™é¸æ¸…å–®ï¼ˆæ­£ä¾‹ + è² ä¾‹ï¼‰ï¼Œä¸¦æ‰“äº‚
#             candidate_items = sampled_negatives + [pos_item]
#             random.shuffle(candidate_items)
#             # print(f"ğŸ§® Candidate items (shuffled): {candidate_items[:10]}...")

#             # âœ… ç¬¬å››æ­¥ï¼šè½‰æˆ tensor ä¸¦é€å…¥æ¨¡å‹è¨ˆç®—åˆ†æ•¸
#             user_tensor = torch.tensor([user_id] * len(candidate_items), device=device)
#             item_tensor = torch.tensor(candidate_items, device=device)
#             link = torch.stack([user_tensor, item_tensor], dim=0)

#             scores = model(source_edge_index, target_edge_index, link, is_source=False).squeeze()
#             top_k_indices = torch.topk(scores, k=top_k).indices.tolist()
#             top_k_items = [candidate_items[i] for i in top_k_indices]

#             # print(f"ğŸ“ˆ Top-{top_k} prediction: {top_k_items}")
#             # print(f"âœ”ï¸ Hit? {'Yes âœ…' if pos_item in top_k_items else 'No âŒ'}")

#             if pos_item in top_k_items:
#                 hit_count += 1
#             total_users += 1

#     hit_ratio = hit_count / total_users if total_users > 0 else 0.0
#     logging.info(f"[HIT_RATIO@{top_k}] Users={total_users}, Hits={hit_count}, Hit Ratio={hit_ratio:.4f}")
#     return hit_ratio

# # ğŸ” çµ±è¨ˆæ¯å€‹ cold item åœ¨ test set ä¸­å‡ºç¾çš„æ¬¡æ•¸ï¼ˆæœ‰å¹¾å€‹ user è²·éï¼‰
# def count_cold_item_occurrences(data, cold_item_set):
#     item_count = {item: 0 for item in cold_item_set}
#     test_link = data.target_test_link.cpu().numpy()
#     for u, i in zip(*test_link):
#         if i in cold_item_set:
#             item_count[i] += 1
#     return item_count

# def find_cold_item_strict(data, target_train_edge_index, target_test_edge_index):
#     import numpy as np
#     from collections import defaultdict

#     train_edges = target_train_edge_index.cpu().numpy()
#     test_edges = target_test_edge_index.cpu().numpy()
#     overlap_users = set(data.raw_overlap_users.cpu().numpy())  # â¬…ï¸ overlap user list

#     train_items = set(train_edges[1])
#     test_user, test_item = test_edges

#     # âœ… å»ºç«‹ test set ä¸­ item â†’ user çš„ mapping
#     item_user_map = defaultdict(set)
#     for u, i in zip(test_user, test_item):
#         if u in overlap_users:
#             item_user_map[i].add(u)

#     candidate_info = []  # å­˜æ”¾ (item_id, user_id, user_source_count)

#     for item, users in item_user_map.items():
#         if item not in train_items and len(users) == 1:
#             user = list(users)[0]

#             # âœ… è¨ˆç®—é€™ä½ user åœ¨ source domain è²·éå¹¾å€‹ item
#             source_edges = data.source_link.cpu()
#             source_items = source_edges[1, source_edges[0] == user]
#             num_bought = len(source_items)

#             candidate_info.append((item, user, num_bought))

#     if not candidate_info:
#         print("âŒ æ‰¾ä¸åˆ°ç¬¦åˆæ¢ä»¶çš„ cold item")
#         return None

#     # âœ… ä¾ç…§ source domain è²·çš„æ•¸é‡åšæ’åºï¼ˆç”±å¤§åˆ°å°ï¼‰
#     candidate_info.sort(key=lambda x: x[2], reverse=True)

#     # selected, seed_user, source_count = candidate_info[100]
#     selected = 2286
#     # çµ±è¨ˆå‡ºç¾æ¬¡æ•¸
#     train_count = (train_edges[1] == selected).sum()
#     test_count = (test_item == selected).sum()

#     print("ğŸ§Š Found cold item:", selected)
#     print("ğŸ”— ASIN:", data.target_id2asin.get(selected, "N/A"))
#     print(f"ğŸ“Š Appears in train set: {train_count} times")
#     print(f"ğŸ“Š Appears in test set : {test_count} times")
#     # print(f"ğŸ‘¤ Seed user ID: {seed_user}")
#     # print(f"ğŸ›ï¸  Bought {source_count} items in source domain")

#     return selected



# def evaluate_er_hit_ratio(
#     model, data, source_edge_index, target_edge_index,
#     cold_item_set,
#     top_k, num_candidates=99,
#     device=None
# ):
#     import random
#     model.eval()

#     all_target_items = set(range(data.num_target_items))
#     user_interactions = get_test_positive_dict(data)
#     sim_users = list(user_interactions.keys())

#     source_edge_index = source_edge_index.to(device)
#     target_edge_index = target_edge_index.to(device)

#     total_users = 0
#     cold_item_hit_count = 0
#     cold_item_ranks = []  # â¬…ï¸ å„²å­˜ cold item è¢«æ’é€²å»æ™‚çš„æ’å

#     with torch.no_grad():
#         for user_id in sim_users:
#             # å»ºç«‹å€™é¸æ± 
#             negative_pool = list(all_target_items - cold_item_set)
#             if len(negative_pool) < num_candidates:
#                 continue

#             sampled_items = random.sample(negative_pool, num_candidates)
#             sampled_items += list(cold_item_set)
#             sampled_items = list(set(sampled_items))
#             random.shuffle(sampled_items)

#             user_tensor = torch.tensor([user_id] * len(sampled_items), device=device)
#             item_tensor = torch.tensor(sampled_items, device=device)
#             link = torch.stack([user_tensor, item_tensor], dim=0)

#             scores = model(source_edge_index, target_edge_index, link, is_source=False).squeeze()
#             scores_list = scores.tolist()

#             # å°å‡ºæ¯å€‹ item çš„åˆ†æ•¸
#             # print(f"\n=== [User {user_id}] ===")
#             # for item, score in zip(sampled_items, scores_list):
#             #     tag = "ğŸ§Š COLD" if item in cold_item_set else ""
#             #     print(f"Item {item:4d} | Score: {score:.4f} {tag}")

#             # è¨ˆç®—æ’åº
#             item_score_pairs = list(zip(sampled_items, scores_list))
#             item_score_pairs.sort(key=lambda x: x[1], reverse=True)
#             sorted_items = [item for item, _ in item_score_pairs]

#             # å°å‡º cold item çš„æ’å
#             for cold_item in cold_item_set:
#                 if cold_item in sorted_items:
#                     rank = sorted_items.index(cold_item) + 1
#                     # print(f"ğŸ” Cold item {cold_item} ranked #{rank} / {len(sorted_items)}")

#             top_k_items = sorted_items[:top_k]


#             # â¬‡ï¸ çµ±è¨ˆå‘½ä¸­èˆ‡æ’å
#             cold_hits = [item for item in top_k_items if item in cold_item_set]
#             if cold_hits:
#                 cold_item_hit_count += 1
#                 for cold_item in cold_hits:
#                     rank = top_k_items.index(cold_item) + 1  # 1-based rank
#                     cold_item_ranks.append(rank)

#             total_users += 1

#     er_ratio = cold_item_hit_count / total_users if total_users > 0 else 0.0
#     avg_rank = sum(cold_item_ranks) / len(cold_item_ranks) if cold_item_ranks else -1
#     median_rank = (
#         sorted(cold_item_ranks)[len(cold_item_ranks) // 2] if cold_item_ranks else -1
#     )

#     logging.info(f"[ER@{top_k}] Users={total_users}, Cold Item Hits={cold_item_hit_count}, ER Ratio={er_ratio:.4f}")
#     # logging.info(f"[ER@{top_k}] Cold item avg rank: {avg_rank:.2f}, median rank: {median_rank}")

#     return er_ratio

# def evaluate_multiple_topk(model, data, source_edge_index, target_edge_index, cold_item_set, device):
#     topk_list = [10, 15, 20, 25, 30, 40, 50, 60, 70, 80, 90, 100]
#     print("\nğŸ“Š Evaluation for multiple top-K values:")
#     for k in topk_list:
#         hr = evaluate_hit_ratio(
#             model=model,
#             data=data,
#             source_edge_index=source_edge_index,
#             target_edge_index=target_edge_index,
#             top_k=k,
#             num_candidates=99,
#             device=device
#         )

#         er = evaluate_er_hit_ratio(
#             model=model,
#             data=data,
#             source_edge_index=source_edge_index,
#             target_edge_index=target_edge_index,
#             cold_item_set=cold_item_set,
#             top_k=k,
#             num_candidates=99,
#             device=device
#         )
# def train(model, perceptor, data, args):
#     device = args.device
#     data = data.to(device)
#     model = model.to(device)
#     perceptor = perceptor.to(device)

#     (
#         source_edge_index,
#         source_label,
#         source_link,
#         target_train_edge_index,
#         target_train_label,
#         target_train_link,
#         target_valid_link,
#         target_valid_label,
#         target_test_link,
#         target_test_label,
#         target_test_edge_index,  # âœ… æ–°å¢é€™ä¸€é …
#     ) = link_split(data)
#     data.target_test_link = target_test_link
#     source_set_size = source_link.shape[1]
#     train_set_size = target_train_link.shape[1]
#     val_set_size = target_valid_link.shape[1]
#     test_set_size = target_test_link.shape[1]
#     logging.info(f"Train set size: {train_set_size}")
#     logging.info(f"Valid set size: {val_set_size}")
#     logging.info(f"Test set size: {test_set_size}")

#     target_train_set = Dataset(
#         target_train_link.to("cpu"),
#         target_train_label.to("cpu"),
#     )
#     target_train_loader = DataLoader(
#         target_train_set,
#         batch_size=args.batch_size,
#         shuffle=True,
#         num_workers=args.num_workers,
#         collate_fn=target_train_set.collate_fn,
#     )

#     source_batch_size = int(args.batch_size * train_set_size / source_set_size)
#     source_train_set = Dataset(source_link.to("cpu"), source_label.to("cpu"))
#     source_train_loader = DataLoader(
#         source_train_set,
#         batch_size=source_batch_size,
#         shuffle=True,
#         num_workers=args.num_workers,
#         collate_fn=source_train_set.collate_fn,
#     )

#     target_meta_loader = DataLoader(
#         target_train_set,
#         batch_size=args.meta_batch_size,
#         shuffle=True,
#         num_workers=args.num_workers,
#         collate_fn=target_train_set.collate_fn,
#     )
#     target_meta_iter = iter(target_meta_loader)
#     source_meta_batch_size = int(
#         args.meta_batch_size * train_set_size / source_set_size
#     )
#     source_meta_loader = DataLoader(
#         source_train_set,
#         batch_size=source_meta_batch_size,
#         shuffle=True,
#         num_workers=args.num_workers,
#         collate_fn=source_train_set.collate_fn,
#     )

#     optimizer = torch.optim.AdamW(
#         model.parameters(), lr=args.lr, weight_decay=args.weight_decay
#     )
#     lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
#         optimizer, T_max=args.epochs
#     )

#     perceptor_optimizer = torch.optim.Adam(
#         perceptor.parameters(), lr=args.lr, weight_decay=args.weight_decay
#     )
#     meta_optimizer = MetaOptimizer(
#         meta_optimizer=perceptor_optimizer,
#         hpo_lr=args.hpo_lr,
#         truncate_iter=3,
#         max_grad_norm=10,
#     )

#     model_param = [
#         param for name, param in model.named_parameters() if "preds" not in name
#     ]
#     replace_param = [
#         param for name, param in model.named_parameters() if name.startswith("replace")
#     ]
#     replace_optimizer = torch.optim.Adam(replace_param, lr=args.lr)
#     replace_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
#         replace_optimizer, T_max=args.T_max
#     )

#     early_stopping = EarlyStopping(
#         patience=args.patience,
#         verbose=True,
#         path=args.model_path,
#         trace_func=logging.info,
#     )

#     criterion = nn.BCELoss(reduction="none")
#     iteration = 0
#     for epoch in range(args.epochs):
#         for (source_link, source_label), (target_link, target_label) in zip(
#             source_train_loader, target_train_loader
#         ):
#             torch.cuda.empty_cache()
#             source_link = source_link.to(device)
#             source_label = source_label.to(device)
#             target_link = target_link.to(device)
#             target_label = target_label.to(device)
#             weight_source = perceptor(source_link[1], source_edge_index, model)

#             optimizer.zero_grad()
#             source_out = model(
#                 source_edge_index, target_train_edge_index, source_link, is_source=True
#             ).squeeze()
#             target_out = model(
#                 source_edge_index, target_train_edge_index, target_link, is_source=False
#             ).squeeze()
#             source_loss = (
#                 criterion(source_out, source_label).reshape(-1, 1) * weight_source
#             ).sum()
#             target_loss = criterion(target_out, target_label).mean()
#             loss = source_loss + target_loss if args.use_meta else target_loss
#             loss.backward()
#             optimizer.step()

#             iteration += 1
#             if (
#                 args.use_source
#                 and args.use_meta
#                 and iteration % args.meta_interval == 0
#             ):
#                 logging.info(f"Entering meta optimization, iteration: {iteration}")
#                 meta_optimizeation(
#                     target_meta_loader,
#                     replace_optimizer,
#                     model,
#                     args,
#                     criterion,
#                     replace_scheduler,
#                     source_edge_index,
#                     target_train_edge_index,
#                 )

#                 try:
#                     target_meta_link, target_meta_label = next(target_meta_iter)
#                 except StopIteration:
#                     target_meta_iter = iter(target_meta_loader)
#                     target_meta_link, target_meta_label = next(target_meta_iter)

#                 target_meta_link, target_meta_label = (
#                     target_meta_link.to(device),
#                     target_meta_label.to(device),
#                 )
#                 optimizer.zero_grad()
#                 target_out = model(
#                     source_edge_index,
#                     target_train_edge_index,
#                     target_meta_link,
#                     is_source=False,
#                 ).squeeze()
#                 meta_loss = criterion(target_out, target_meta_label).mean()

#                 for (source_link, source_label), (target_link, target_label) in zip(
#                     source_meta_loader, target_meta_loader
#                 ):
#                     source_link, source_label = source_link.to(device), source_label.to(
#                         device
#                     )
#                     target_link, target_label = target_link.to(device), target_label.to(
#                         device
#                     )
#                     weight_source = perceptor(source_link[1], source_edge_index, model)

#                     optimizer.zero_grad()
#                     source_out = model(
#                         source_edge_index,
#                         target_train_edge_index,
#                         source_link,
#                         is_source=True,
#                     ).squeeze()
#                     target_out = model(
#                         source_edge_index,
#                         target_train_edge_index,
#                         target_link,
#                         is_source=False,
#                     ).squeeze()
#                     source_loss = (
#                         criterion(source_out, source_label).reshape(-1, 1)
#                         * weight_source
#                     ).sum()
#                     target_loss = criterion(target_out, target_label).mean()
#                     meta_train_loss = (
#                         source_loss + target_loss if args.use_meta else target_loss
#                     )
#                     break

#                 torch.cuda.empty_cache()
#                 meta_optimizer.step(
#                     train_loss=meta_train_loss,
#                     val_loss=meta_loss,
#                     aux_params=list(perceptor.parameters()),
#                     parameters=model_param,
#                     return_grads=True,
#                     entropy=None,
#                 )
#         train_auc = evaluate(
#             "Train",
#             model,
#             source_edge_index,
#             target_train_edge_index,
#             target_train_link,
#             target_train_label,
#         )
#         val_auc = evaluate(
#             "Valid",
#             model,
#             source_edge_index,
#             target_train_edge_index,
#             target_valid_link,
#             target_valid_label,
#         )

#         logging.info(
#             f"[Epoch: {epoch}]Train Loss: {loss:.4f}, Train AUC: {train_auc:.4f}, Valid AUC: {val_auc:.4f}"
#         )
#         wandb.log(
#             {
#                 "loss": loss,
#                 "train_auc": train_auc,
#                 "val_auc": val_auc
#             },
#             step=epoch,
#         )

#         early_stopping(val_auc, model)
#         if early_stopping.early_stop:
#             logging.info("Early stopping")
#             break

#         lr_scheduler.step()

#     model = load_model(args).to(device)
#     evaluate_hit_ratio(
#         model=model,
#         data=data,
#         source_edge_index=source_edge_index,
#         target_edge_index=target_train_edge_index,  # âœ… æ­£ç¢ºå‚³å…¥æ¸¬è©¦é›† edge_index
#         top_k=args.top_k,
#         num_candidates=99,
#         device=device,
#     )
#     cold_item_id = 2286
   
#     id = find_cold_item_strict(data, data.target_train_edge_index, data.target_test_edge_index)
#     print("id======", id)

#     if cold_item_id is not None:
#         evaluate_er_hit_ratio(
#             model=model,
#             data=data,
#             source_edge_index=source_edge_index,
#             target_edge_index=target_train_edge_index,
#             cold_item_set={cold_item_id},
#             top_k=args.top_k,
#             num_candidates=99,
#             device=device,
#         )

#     # logging.info(f"Hit Ratio (no injection): {pre_hit_ratio:.4f}")
#     test_auc = evaluate(
#         "Test",
#         model,
#         source_edge_index,
#         target_train_edge_index,
#         target_test_link,
#         target_test_label,
#     )
#     logging.info(f"Test AUC: {test_auc:.4f}")
#     wandb.log({"Test AUC": test_auc})
#     evaluate_multiple_topk(
#     model=model,
#     data=data,
#     source_edge_index=source_edge_index,
#     target_edge_index=target_train_edge_index,
#     cold_item_set={2286},   # æ³¨æ„é€™é‚Šæ˜¯ setï¼Œä¸æ˜¯ cold_item_id=
#     device=device
#     )