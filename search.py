import argparse
import logging
import os
import time

import wandb

from collections import Counter

from dataset import CrossDomain
from model import Model, Perceptor
from train import train
from utils import set_logging, set_seed


# def inject_fake_edges( 
#     data,
#     source_edge_index,
#     target_edge_index,
#     user_fraction=0.01,        # å¾ raw_overlap_users ä¸­é¸å¤šå°‘æ¯”ä¾‹ user
#     item_fraction=0.5,         # æ¯ä½ user æ¨¡ä»¿å¤šå°‘æ¯”ä¾‹ seed user çš„è¡Œç‚º
#     id2asin=None,
#     cold_item_ids=None,
#     seed_user=None,
#     log_detail=False,
#     args=None
# ):
#     import torch
#     import random
#     from collections import defaultdict, Counter
#     import logging

#     device = source_edge_index.device
#     logger = logging.getLogger(__name__)
#     logger.info(f"[inject_fake_edges] Before injection: source_edge_index has {source_edge_index.shape[1]} edges")

#     # ç¢ºä¿ cold_item_ids ç‚º list
#     if isinstance(cold_item_ids, int):
#         cold_item_ids = [cold_item_ids]

#     if args is not None:
#         args.cold_item_ids = cold_item_ids

#     # å°å‡ºå†·é–€å•†å“è³‡è¨Š
#     if log_detail:
#         logger.info("===== å†·é–€å•†å“åˆ—è¡¨ =====")
#         for item_id in cold_item_ids:
#             asin = id2asin[item_id] if id2asin and item_id in id2asin else f"ID:{item_id}"
#             logger.info(f"[RANKING] å†·é–€å•†å“ ID: {item_id}, ASIN: {asin}")

#     # === STEP 1: æ±ºå®š seed userï¼ˆå†·é–€å•†å“äº’å‹•è€…ï¼‰
#     user2cold_items = defaultdict(list)

#     if seed_user is not None:
#         cold_users = [seed_user]
#         logger.info(f"[inject_fake_edges] âœ… Using manually specified seed user: {seed_user}")
#     else:
#         for u, i in zip(target_edge_index[0].tolist(), target_edge_index[1].tolist()):
#             if i in cold_item_ids:
#                 user2cold_items[u].append(i)
#         cold_users = list(user2cold_items.keys())
#         logger.info(f"[inject_fake_edges] Found {len(cold_users)} cold users: {cold_users}")

#     # === STEP 2: å»ºç«‹ source domain user-item å°æ‡‰è¡¨
#     user_item_dict = defaultdict(set)
#     for u, i in zip(source_edge_index[0].tolist(), source_edge_index[1].tolist()):
#         user_item_dict[u].add(i)

#     if log_detail:
#         logger.info(f"[inject_fake_edges] Sample of user-item mappings (å‰5ç”¨æˆ¶):")
#         for idx, (u, items) in enumerate(user_item_dict.items()):
#             logger.info(f"  User {u}: {list(items)[:10]} (å…±{len(items)}é …ç›®)")
#             if idx >= 4:
#                 break
#         if seed_user is not None:
#             seed_items = user_item_dict.get(seed_user, set())
#             logger.info(f"[inject_fake_edges] Seed user {seed_user} è¡Œç‚ºæ•¸é‡: {len(seed_items)}ï¼Œç¯„ä¾‹: {list(seed_items)[:10]}")

#     # === STEP 3: å¾ overlap users ä¸­é¸ attack users
#     overlap_users_list = data.raw_overlap_users.tolist()
#     num_fake_users = max(1, int(len(overlap_users_list) * user_fraction))
#     selected_users = random.sample(overlap_users_list, num_fake_users)

#     logger.info(f"[inject_fake_edges] Total overlap users: {len(overlap_users_list)}")
#     logger.info(f"[inject_fake_edges] Selecting {num_fake_users} users (~{user_fraction*100:.2f}%) to inject fake edges.")
#     logger.info(f"[inject_fake_edges] é¸ä¸­ç”¨æˆ¶ç¯„ä¾‹ï¼ˆæœ€å¤šå‰10å€‹ï¼‰: {selected_users[:10]}")

#     # === STEP 4: æ³¨å…¥ source domain å‡é‚Š
#     source_fake_edges = []
#     target_fake_edges = []
#     sim_users = set()

#     for u2 in selected_users:
#         sim_users.add(u2)
#         seed_user_for_injection = random.choice(cold_users)
#         seed_items = list(user_item_dict.get(seed_user_for_injection, []))

#         if not seed_items:
#             top_items = [i for i, _ in Counter(source_edge_index[1].tolist()).most_common(10)]
#             seed_items = top_items
#             logger.warning(f"[inject_fake_edges] Seed user {seed_user_for_injection} ç„¡ source è¡Œç‚ºï¼Œæ”¹ç”¨ç†±é–€å•†å“ {top_items}")

#         num_items_to_inject = max(1, int(len(seed_items) * item_fraction))
#         sampled_items = random.sample(seed_items, num_items_to_inject)

#         if log_detail:
#             logger.info(f"[inject_fake_edges] ç”¨æˆ¶ {u2} æ³¨å…¥ {num_items_to_inject} ä»¶å•†å“ï¼Œæ¨¡ä»¿ç¨®å­ç”¨æˆ¶ {seed_user_for_injection}")

#         for item in sampled_items:
#             source_fake_edges.append((u2, item))

#         # åŒæ™‚ç‚º target domain æ³¨å…¥ cold itemï¼ˆå·² + offsetï¼‰
#         for item in cold_item_ids:
#             target_fake_edges.append((u2, item + data.num_users))

#     # === STEP 5: åˆä½µé‚Šé›†
#     def combine_edges(original, fake):
#         if fake:
#             u, i = zip(*fake)
#             u_tensor = torch.tensor(u, dtype=torch.long).to(device)
#             i_tensor = torch.tensor(i, dtype=torch.long).to(device)
#             fake_tensor = torch.stack([u_tensor, i_tensor], dim=0)
#             return torch.cat([original, fake_tensor], dim=1)
#         return original

#     new_source_edge_index = combine_edges(source_edge_index, source_fake_edges)
#     new_target_edge_index = combine_edges(target_edge_index, target_fake_edges)

#     logger.info(f"[inject_fake_edges] æ³¨å…¥äº† {len(source_fake_edges)} æ¢ source å‡é‚Š")
#     logger.info(f"[inject_fake_edges] æ³¨å…¥äº† {len(target_fake_edges)} æ¢ target å‡é‚Š")
#     logger.info(f"[inject_fake_edges] æ³¨å…¥å¾Œ source_edge_index é‚Šæ•¸: {new_source_edge_index.shape[1]}")
#     logger.info(f"[inject_fake_edges] æ³¨å…¥å¾Œ target_edge_index é‚Šæ•¸: {new_target_edge_index.shape[1]}")
#     logger.info(f"[inject_fake_edges] ç¸½æ¨¡æ“¬ç”¨æˆ¶æ•¸: {len(sim_users)}")

#     return new_source_edge_index, new_target_edge_index, cold_item_ids, list(sim_users)

def inject_fake_edges(
    data,
    model,
    source_edge_index,
    target_edge_index,
    cold_item_id,
    user_fraction=0.01,
    device=None,
    log_detail=True,
    args=None,
    inject_source=True,  # âœ… æ˜¯å¦æ³¨å…¥ source å‡é‚Š
    inject_target=True,  # âœ… æ˜¯å¦æ³¨å…¥ target å‡é‚Š
    source_edge_fraction=None, 
):
    import torch
    import random
    import logging

    logger = logging.getLogger(__name__)
    device = device or source_edge_index.device
    num_users = data.num_users

    source_edge_index = source_edge_index.to(device)
    target_edge_index = target_edge_index.to(device)
    model = model.to(device)

    logger.info(f"[inject_fake_edges] Start. Original edges: {source_edge_index.shape[1]}")

    # === Step 1: é¸å‡ºå° cold item é æ¸¬åˆ†æ•¸æœ€é«˜çš„ overlap users ===
    overlap_users = data.raw_overlap_users.tolist()
    user_tensor = torch.tensor(overlap_users, device=device)
    item_tensor = torch.tensor([cold_item_id] * len(overlap_users), device=device)
    link = torch.stack([user_tensor, item_tensor], dim=0)

    model.eval()
    with torch.no_grad():
        scores = model(source_edge_index, target_edge_index, link, is_source=False).view(-1)

    top_k = max(1, int(len(overlap_users) * user_fraction))
    top_scores, top_indices = torch.topk(scores, top_k)
    selected_users = [overlap_users[i] for i in top_indices.tolist()]
    logger.info(f"[inject_fake_edges] Selected {len(selected_users)} users with top predicted score for cold item")

    # ğŸ” å°å‡ºå‰13ä½çš„ä½¿ç”¨è€…èˆ‡é æ¸¬åˆ†æ•¸
    print(f"ğŸ” Top {len(selected_users)} selected user IDs and scores (æœ€å¤šå‰28å€‹):")
    for rank in range(min(28, len(selected_users))):
        uid = selected_users[rank]
        score = top_scores[rank].item()
        print(f"  #{rank+1}: user_id = {uid}, score = {score:.6f}")



    # === Step 2: æ‰¾å‡º seed userï¼ˆèˆ‡ cold item æœ‰äº¤äº’çš„ userï¼‰ ===
    tgt_u, tgt_i = data.target_train_edge_index


    # seed_users = [u.item() for u, i in zip(tgt_u, tgt_i) if i.item() == cold_item_id]
    # seed_users = list(set(seed_users))
    seed_users =2543
    if not seed_users:
        logger.warning(f"[inject_fake_edges] No seed users found for cold item {cold_item_id}")
        return source_edge_index, target_edge_index, [cold_item_id], selected_users
    seed_user = 2543  # å‡è¨­åªæœ‰ä¸€å€‹ seed user
    logger.info(f"[inject_fake_edges] Seed user for cold item: {seed_user}")

    # === Step 3: å–å¾— seed user åœ¨ source domain çš„æ‰€æœ‰è¡Œç‚º ===
    su, si = source_edge_index[0].tolist(), source_edge_index[1].tolist()
    seed_source_items = [i for u, i in zip(su, si) if u == seed_user]
    seed_source_items = list(set(seed_source_items))
    logger.info(f"[inject_fake_edges] Seed user has {len(seed_source_items)} source domain items")

    # === Step 4: å»ºç«‹ fake edge çµ¦ target domain æ”»æ“Šç”¨æˆ¶ ===
    fake_source_edges = [(u, i) for u in selected_users for i in seed_source_items]
    fake_target_edges = [(u, cold_item_id) for u in selected_users]

    # === Step 5: åˆä½µ source å‡é‚Šï¼ˆè¦–æ¢ä»¶æ³¨å…¥ï¼‰ ===
    # === Step 5: åˆä½µ source å‡é‚Šï¼ˆè¦–æ¢ä»¶æ³¨å…¥ï¼‰ ===
    if inject_source and fake_source_edges:
        # âœ… éš¨æ©ŸæŠ½å–æŒ‡å®šæ¯”ä¾‹çš„å‡é‚Š
        if source_edge_fraction < 1.0:
            sample_size = int(len(fake_source_edges) * source_edge_fraction)
            fake_source_edges = random.sample(fake_source_edges, sample_size)
            logger.info(f"[inject_fake_edges] åƒ…ä½¿ç”¨ {sample_size} æ¢ source å‡é‚Š (æ¯”ä¾‹={source_edge_fraction})")

        su, si = zip(*fake_source_edges)
        su_tensor = torch.tensor(su, dtype=torch.long, device=device)
        si_tensor = torch.tensor(si, dtype=torch.long, device=device)
        new_source_edge_index = torch.cat(
            [source_edge_index, torch.stack([su_tensor, si_tensor], dim=0)], dim=1
        )
        logger.info(f"[inject_fake_edges] æ³¨å…¥ {len(fake_source_edges)} æ¢ source å‡é‚Š (copy seed user è¡Œç‚º)")
    else:
        new_source_edge_index = source_edge_index
        logger.info(f"[inject_fake_edges] æœªæ³¨å…¥ source å‡é‚Š")

    # === Step 6: åˆä½µ target å‡é‚Šï¼ˆè¦–æ¢ä»¶æ³¨å…¥ï¼‰ ===
    if inject_target and fake_target_edges:
        tu, ti = zip(*fake_target_edges)
        tu_tensor = torch.tensor(tu, dtype=torch.long, device=device)
        ti_tensor = torch.tensor(ti, dtype=torch.long, device=device)
        new_target_edge_index = torch.cat(
            [target_edge_index, torch.stack([tu_tensor, ti_tensor], dim=0)], dim=1
        )
        logger.info(f"[inject_fake_edges] æ³¨å…¥ {len(fake_target_edges)} æ¢ target å‡é‚Š (cold item)")
    else:
        new_target_edge_index = target_edge_index
        logger.info(f"[inject_fake_edges] æœªæ³¨å…¥ target å‡é‚Š")

    logger.info(f"[inject_fake_edges] æ–° source_edge_index é‚Šæ•¸: {new_source_edge_index.shape[1]}")
    logger.info(f"[inject_fake_edges] æ–° target_edge_index é‚Šæ•¸: {new_target_edge_index.shape[1]}")

    return new_source_edge_index, new_target_edge_index, [cold_item_id], selected_users

def search(args):
    args.search = True

    wandb.init(project="BiGNAS", config=args)
    set_seed(args.seed)
    set_logging()

    logging.info(f"args: {args}")

    dataset = CrossDomain(
        root=args.root,
        categories=args.categories,
        target=args.target,
        use_source=args.use_source,
    )

    data = dataset[0]
    args.num_users = data.num_users
    args.num_source_items = data.num_source_items
    args.num_target_items = data.num_target_items
    logging.info(f"data: {data}")

    DATE_FORMAT = "%Y-%m-%d_%H:%M:%S"
    args.model_path = os.path.join(
        args.model_dir,
        f'{time.strftime(DATE_FORMAT, time.localtime())}_{"_".join(args.categories)}.pt',
    )

    model = Model(args)
    perceptor = Perceptor(args)
    logging.info(f"model: {model}")

    # å–å‡º source èˆ‡ target çš„ edge_index
    source_edge_index = data.source_link.to(args.device)  # ä¸æ˜¯ source_edge_indexï¼Œæ˜¯ source_link

    target_edge_index = data.target_train_edge_index.to(args.device)

    # ä½ æƒ³è¦æ³¨å…¥çš„å†·é–€å•†å“ï¼Œå¯ä»¥æ”¹æˆä½ è‡ªå·±çš„IDåˆ—è¡¨
    # cold_item_ids  = args.cold_item_ids
    # è™•ç†å†·é–€å•†å“ ID åˆ—è¡¨ï¼ˆä¾†è‡ª argparseï¼‰
    cold_item_ids = args.cold_item_ids if isinstance(args.cold_item_ids, list) else [args.cold_item_ids]
    cold_item_id = cold_item_ids[0]  # ç›®å‰åªæ”¯æ´å–®ä¸€ cold item


    # æ³¨å…¥ fake edges
    # fake_source_edge_index, fake_target_edge_index, cold_items, sim_users = inject_fake_edges(
    #     data=data,
    #     source_edge_index=source_edge_index,
    #     target_edge_index=target_edge_index,
    #     user_fraction=0.01,
    #     item_fraction=1,
    #     cold_item_ids=cold_item_ids,
    #     seed_user=2543,
    #     log_detail=True,
    #     args=args,
    # )
    fake_source_edge_index, fake_target_edge_index, cold_items, sim_users = inject_fake_edges(
        data=data,
        model=model,
        source_edge_index=source_edge_index,
        target_edge_index=target_edge_index,
        cold_item_id=cold_item_id,
        user_fraction=0.01,
        device=args.device,
        args=args,
        inject_source=True,
        inject_target=True,
        source_edge_fraction=0.1
    )

    # ä½¿ç”¨ç¯¡æ”¹å¾Œçš„ source_edge_index é€²è¡Œè¨“ç·´
    train(
        model,
        perceptor,
        data,
        args,
        source_edge_index=fake_source_edge_index,
        target_edge_index=fake_target_edge_index,  # âœ… åŠ ä¸Šé€™è¡Œ
    )


##############################
# def search(args):
#     args.search = True

#     wandb.init(project="BiGNAS", config=args)
#     set_seed(args.seed)
#     set_logging()

#     logging.info(f"args: {args}")

#     dataset = CrossDomain(
#         root=args.root,
#         categories=args.categories,
#         target=args.target,
#         use_source=args.use_source,
#     )

#     data = dataset[0]
#     args.num_users = data.num_users
#     args.num_source_items = data.num_source_items
#     args.num_target_items = data.num_target_items
#     logging.info(f"data: {data}")

#     DATE_FORMAT = "%Y-%m-%d_%H:%M:%S"
#     args.model_path = os.path.join(
#         args.model_dir,
#         f'{time.strftime(DATE_FORMAT, time.localtime())}_{"_".join(args.categories)}.pt',
#     )

#     model = Model(args)
#     perceptor = Perceptor(args)
#     logging.info(f"model: {model}")
#     train(model, perceptor, data, args)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    # device & mode settings
    parser.add_argument("--seed", type=int, default=2023)
    parser.add_argument("--device", type=str, default="cuda:1")
    parser.add_argument("--num-workers", type=int, default=6)
    parser.add_argument("--search", default=False, action="store_true")
    parser.add_argument("--use-meta", default=False, action="store_true")
    parser.add_argument("--use-source", default=False, action="store_true")

    # dataset settings
    parser.add_argument(
        "--categories", type=str, nargs="+", default=["Electronic", "Clothing"]
    )
    parser.add_argument("--target", type=str, default="Clothing")
    parser.add_argument("--root", type=str, default="data/")

    # model settings
    parser.add_argument("--aggr", type=str, default="mean")
    parser.add_argument("--bn", type=bool, default=False)
    parser.add_argument("--num-layers", type=int, default=2)
    parser.add_argument("--hidden-dim", type=int, default=32)
    parser.add_argument("--embedding-dim", type=int, default=32)
    parser.add_argument("--model-dir", type=str, default="./save/")

    # supernet settings
    parser.add_argument(
        "--space",
        type=str,
        nargs="+",
        default=["gcn", "gatv2", "sage", "lightgcn", "linear"],
    )
    parser.add_argument("--warm-up", type=float, default=0.1)
    parser.add_argument("--repeat", type=int, default=6)
    parser.add_argument("--T", type=int, default=1)
    parser.add_argument("--entropy", type=float, default=0.0)

    # training settings
    parser.add_argument("--batch-size", type=int, default=1024)
    parser.add_argument("--epochs", type=int, default=1000)
    parser.add_argument("--patience", type=int, default=3)
    parser.add_argument("--dropout", type=float, default=0.1)
    parser.add_argument("--weight-decay", type=float, default=0.0)
    parser.add_argument("--lr", type=float, default=0.01)
    parser.add_argument("--eta-min", type=float, default=0.001)
    parser.add_argument("--T-max", type=int, default=10)
    parser.add_argument("--top_k", type=int, default=15, help="Top-K for hit ratio evaluation")
    parser.add_argument("--cold_item_ids", type=int, default=None, help="å†·é–€å•†å“çš„ target item ID")

    # meta settings
    parser.add_argument("--meta-interval", type=int, default=50)
    parser.add_argument("--meta-num-layers", type=int, default=2)
    parser.add_argument("--meta-hidden-dim", type=int, default=32)
    parser.add_argument("--meta-batch-size", type=int, default=512)
    parser.add_argument("--conv-lr", type=float, default=1)
    parser.add_argument("--hpo-lr", type=float, default=0.01)
    parser.add_argument("--descent-step", type=int, default=10)
    parser.add_argument("--meta-op", type=str, default="gat")

    args = parser.parse_args()
    search(args)